{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up an Anaconda environment for implementing the Transformer model in PyTorch, follow these steps:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Create a New Conda Environment**\n",
    "Open a terminal and run:\n",
    "```bash\n",
    "conda create --name attention-is-all-you-need python=3.12\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Activate the Environment**\n",
    "```bash\n",
    "conda activate attention-is-all-you-need\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Install PyTorch**\n",
    "For GPU (CUDA):\n",
    "```bash\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "```\n",
    "For CPU (if you don’t have a compatible GPU):\n",
    "```bash\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "```\n",
    "Check if PyTorch is installed correctly:\n",
    "```python\n",
    "python -c \"import torch; print(torch.__version__)\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Install Essential Libraries**\n",
    "```bash\n",
    "pip install numpy pandas matplotlib tqdm\n",
    "```\n",
    "- `numpy`: Tensor operations\n",
    "- `pandas`: Data handling (optional, useful for datasets)\n",
    "- `matplotlib`: Visualization\n",
    "- `tqdm`: Progress bars for training\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Install NLP Libraries (If Needed)**\n",
    "```bash\n",
    "pip install transformers datasets tokenizers sentencepiece\n",
    "```\n",
    "- `transformers`: Pretrained models from Hugging Face (optional)\n",
    "- `datasets`: NLP datasets from Hugging Face\n",
    "- `tokenizers`: Efficient tokenization\n",
    "- `sentencepiece`: Subword tokenization (used in original Transformer)\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Install Jupyter Notebook (Optional)**\n",
    "If you want to develop in Jupyter:\n",
    "```bash\n",
    "conda install jupyter\n",
    "```\n",
    "Then start Jupyter:\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Verify Everything**\n",
    "Run the following to ensure your environment is properly set up:\n",
    "```python\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Save the Environment (Optional)**\n",
    "To export your environment for reproducibility:\n",
    "```bash\n",
    "conda env export > environment.yml\n",
    "```\n",
    "To recreate it later:\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int):\n",
    "        \"\"\"\n",
    "        Initializes the embedding layer.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Number of unique tokens in the vocabulary.\n",
    "            d_model (int): Dimension of the embedding vectors.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Define the embedding layer that maps token indices to dense vectors.\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)  \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for token embedding.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor of shape (batch_size, seq_len) containing token indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, seq_len, d_model) containing embedded representations.\n",
    "        \"\"\"\n",
    "        # TODO: Implement the lookup operation using the embedding layer.\n",
    "        embedded = self.embedding(x)  \n",
    "\n",
    "        return embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def run_tests():\n",
    "    # Test Parameters\n",
    "    vocab_size = 100\n",
    "    d_model = 16\n",
    "    batch_size = 4\n",
    "    seq_len = 10\n",
    "\n",
    "    # Create a sample input tensor\n",
    "    test_input = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "    # Initialize TokenEmbedding\n",
    "    embedding_layer = TokenEmbedding(vocab_size, d_model)\n",
    "\n",
    "    # Test 1: Check Output Shape\n",
    "    output = embedding_layer(test_input)\n",
    "    assert output.shape == (batch_size, seq_len, d_model), f\"Unexpected shape: {output.shape}\"\n",
    "    \n",
    "    # Test 2: Ensure Output is a Tensor of Correct Type\n",
    "    assert isinstance(output, torch.Tensor), \"Output is not a tensor\"\n",
    "    assert output.dtype == torch.float32, f\"Unexpected dtype: {output.dtype}\"\n",
    "    \n",
    "    # Test 3: Check if the Same Token Index Maps to the Same Embedding\n",
    "    index = torch.tensor([[5]])\n",
    "    embedding_1 = embedding_layer(index)\n",
    "    embedding_2 = embedding_layer(index)\n",
    "    assert torch.allclose(embedding_1, embedding_2), \"Embeddings should be identical for the same index\"\n",
    "    \n",
    "    # Test 4: Check if Different Indices Give Different Embeddings\n",
    "    index1 = torch.tensor([[5]])\n",
    "    index2 = torch.tensor([[8]])\n",
    "    embedding_1 = embedding_layer(index1)\n",
    "    embedding_2 = embedding_layer(index2)\n",
    "    assert not torch.allclose(embedding_1, embedding_2), \"Different indices should have different embeddings\"\n",
    "    \n",
    "    # Test 5: Check if Gradients are Computed\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "    assert embedding_layer.embedding.weight.grad is not None, \"Gradients should not be None\"\n",
    "    assert embedding_layer.embedding.weight.grad.shape == (vocab_size, d_model), \"Gradient shape mismatch\"\n",
    "    \n",
    "    print(\"✅ All tests passed successfully!\")\n",
    "\n",
    "# Run all tests\n",
    "run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0233,  0.3579, -0.8141], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = TokenEmbedding(vocab_size=10, d_model=3)\n",
    "embedding_layer(torch.tensor(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        \"\"\"\n",
    "        Initializes positional encoding.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Dimension of the embedding vectors.\n",
    "            max_len (int): Maximum sequence length.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Create a positional encoding matrix of shape (max_len, d_model)\n",
    "        positions = torch.tensor\n",
    "        self.pe = None  \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input embeddings.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor of shape (batch_size, seq_len, d_model) containing input embeddings.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of shape (batch_size, seq_len, d_model) with positional encodings added.\n",
    "        \"\"\"\n",
    "        # TODO: Add positional encodings to input embeddings\n",
    "        return None  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-is-all-you-need",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
